{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "from dependencies import BertModel, tokenizer, label_all_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:48:35.595979700Z",
     "start_time": "2023-11-27T09:48:35.565098900Z"
    }
   },
   "id": "4d543b8ec507fac0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Model\n",
    "Link to model weights https://drive.google.com/file/d/1V3lG0iYt0R8cMe95x3WncNOkCAEdwiEY/view?usp=drive_link"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a4027328467bd8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:47:05.331664200Z",
     "start_time": "2023-11-27T09:47:03.097875400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel()\n",
    "model.load_state_dict(torch.load(\"my_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict one sentence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edccada622485eb"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "ids_to_labels = {0: \"O\", 1: \"B-geo\", 2: \"I-geo\"}\n",
    "\n",
    "def align_word_ids(texts):\n",
    "\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(1 if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids\n",
    "\n",
    "\n",
    "def evaluate_one_text(model, sentence):\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    text = tokenizer(sentence, padding=\"max_length\", max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text[\"attention_mask\"].to(device)\n",
    "    input_id = text[\"input_ids\"].to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
    "    print(sentence)\n",
    "    print(prediction_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:51:55.132854100Z",
     "start_time": "2023-11-27T09:51:55.117077400Z"
    }
   },
   "id": "a16e03f4a3ee4455"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictions\n",
    "Generated sentences using ChatGPT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83c1ca3b66fffc62"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Swiss Matterhorn, with its iconic pyramid shape, stands as a testament to the indomitable spirit of alpinism and the allure of challenging summits.\n",
      "['O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "The Blue Ridge Mountains, draped in a misty morning haze, create an ethereal atmosphere that captivates all who venture into their embrace.\n",
      "['O', 'O', 'B-geo', 'I-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Standing tall in the Cascade Range, Mount Hood commands attention with its snow-capped summit, a beacon visible for miles around.\n",
      "['O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "The Rocky Mountains, with their towering summits and sprawling valleys, harbor a diverse ecosystem and provide a haven for outdoor enthusiasts.\n",
      "['O', 'B-geo', 'I-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "The Sierra Nevada Range, adorned with pristine lakes and towering pine trees, offers a serene retreat for those seeking solace in nature.\n",
      "['O', 'B-geo', 'B-geo', 'I-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "The Atlas Mountains in Morocco unveil a rugged beauty, where ancient traditions and modern life coexist in the shadow of towering peaks.\n",
      "['O', 'B-geo', 'I-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"The Swiss Matterhorn, with its iconic pyramid shape, stands as a testament to the indomitable spirit of alpinism and the allure of challenging summits.\")\n",
    "evaluate_one_text(model, \"The Blue Ridge Mountains, draped in a misty morning haze, create an ethereal atmosphere that captivates all who venture into their embrace.\")\n",
    "evaluate_one_text(model, \"Standing tall in the Cascade Range, Mount Hood commands attention with its snow-capped summit, a beacon visible for miles around.\")\n",
    "evaluate_one_text(model, \"The Rocky Mountains, with their towering summits and sprawling valleys, harbor a diverse ecosystem and provide a haven for outdoor enthusiasts.\")\n",
    "evaluate_one_text(model, \"The Sierra Nevada Range, adorned with pristine lakes and towering pine trees, offers a serene retreat for those seeking solace in nature.\")\n",
    "evaluate_one_text(model, \"The Atlas Mountains in Morocco unveil a rugged beauty, where ancient traditions and modern life coexist in the shadow of towering peaks.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:55:31.567902200Z",
     "start_time": "2023-11-27T09:55:27.218424200Z"
    }
   },
   "id": "907d493b3a7617cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
